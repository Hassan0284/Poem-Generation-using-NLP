{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b265b674",
   "metadata": {
    "id": "b265b674"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a05c65",
   "metadata": {
    "id": "d5a05c65"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "import spacy\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac390ae",
   "metadata": {
    "id": "8ac390ae"
   },
   "source": [
    "# Dataset Loading and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf6f6d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adf6f6d2",
    "outputId": "2894f8b6-c566-41e3-d9e3-f6b1e7f3d681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21289\n",
      "3009\n"
     ]
    }
   ],
   "source": [
    "path=r\"/content/poems.csv\"\n",
    "\n",
    "with open(path,'r',encoding='utf-8-sig') as file:\n",
    "    r=csv.reader(file)\n",
    "    text=[row[0] for row in r if row]\n",
    "\n",
    "nlp=spacy.blank('ur')\n",
    "tokens=[]\n",
    "for i in text:\n",
    "    d=nlp(i)\n",
    "    tokens.extend([token.text for token in d if not re.match(r'[a-zA-Z0-9/\\s\\.\\'\\\"\\+\\-\\,\\’\\?\\!\\@\\؟\\#\\$\\%\\^\\&\\*\\۔\\(\\)\\[\\]\\{\\}\\;\\<\\>\\?\\:\\|\\\\]',token.text)])\n",
    "print(len(tokens))\n",
    "tokens=set(tokens) #keep unique tokens /////*****OPTIMIZATION*****/////\n",
    "print(len(tokens))\n",
    "tokens=list(tokens) #as using list onward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf5b70",
   "metadata": {
    "id": "2fdf5b70"
   },
   "source": [
    "# Functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b380892",
   "metadata": {
    "id": "8b380892"
   },
   "outputs": [],
   "source": [
    "#to generate a simple ngram model\n",
    "def generateNgramModel(tokens, n):\n",
    "    nGramModel = {}\n",
    "    for i in range(len(tokens)-n):\n",
    "        ngram = tuple(tokens[i:i+n])\n",
    "        nextWord = tokens[i+n]\n",
    "        if ngram in nGramModel:\n",
    "            nGramModel[ngram].append(nextWord)\n",
    "        else:\n",
    "            nGramModel[ngram] = [nextWord]\n",
    "    return nGramModel\n",
    "\n",
    "#to generate an ngram model using backward method\n",
    "def generateBackwardNgramModel(tokens, n):\n",
    "    nGramModel = {}\n",
    "    for i in range(n, len(tokens)):  # Iterate starting from n-th word\n",
    "        ngram = tuple(tokens[i-n:i])  # Build ngram from right context\n",
    "        previousWord = tokens[i-n-1]  # Word preceding the ngram\n",
    "        if ngram in nGramModel:\n",
    "            nGramModel[ngram].append(previousWord)\n",
    "        else:\n",
    "            nGramModel[ngram] = [previousWord]\n",
    "    return nGramModel\n",
    "\n",
    "\n",
    "#to generate a single verse using the specified model\n",
    "def generateVerse(model, verseLength, previousEndingWord=None):\n",
    "    #randomly select the starting word\n",
    "    startingWord = random.choice(list(model.keys()))\n",
    "    verse = list(startingWord)\n",
    "    for i in range(verseLength - len(startingWord)):\n",
    "        #predict the next word based on the model\n",
    "        if tuple(verse[-(len(startingWord)):]) in model:\n",
    "            nextWord = random.choice(model[tuple(verse[-(len(startingWord)):])])\n",
    "        else:\n",
    "            nextWord = random.choice(tokens)  #randomly choose if not found\n",
    "        verse.append(nextWord)\n",
    "    if previousEndingWord:\n",
    "        #ensure the last word rhymes with the previous ending word /////*****BONUS*****/////\n",
    "        endingWord = findRhymingWord(verse[-1], previousEndingWord, tokens)\n",
    "        verse[-1] = endingWord\n",
    "    return \" \".join(verse), verse[-1]  #return verse and last word\n",
    "\n",
    "#to find a rhyming word\n",
    "def findRhymingWord(word, previousWord, tokens, n=3):\n",
    "    rhymes = set()\n",
    "    for token in tokens:\n",
    "        if (token != word and token.endswith(word[-n:])) or (token != previousWord and token.endswith(previousWord[-n:])):\n",
    "            rhymes.add(token)\n",
    "    #keep only the top 3 rhyming words\n",
    "    rhymes = list(rhymes)\n",
    "    topRhymes = nlargest(5, rhymes, key=rhymes.count)\n",
    "    if topRhymes:\n",
    "        return random.choice(topRhymes)\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "#function to generate a stanza\n",
    "def generateStanza(model, verseLength, numOfVerses):\n",
    "    stanza = []\n",
    "    previousEndingWord = None\n",
    "    for _ in range(numOfVerses):\n",
    "        verse, previousEndingWord = generateVerse(model, verseLength, previousEndingWord)\n",
    "        stanza.append(verse)\n",
    "    return stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97546b1",
   "metadata": {
    "id": "d97546b1"
   },
   "source": [
    "# Generate unigram, bigram, and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed908730",
   "metadata": {
    "id": "ed908730"
   },
   "outputs": [],
   "source": [
    "unigramModel = generateBackwardNgramModel(tokens, 1)\n",
    "bigramModel = generateBackwardNgramModel(tokens, 2)\n",
    "trigramModel = generateBackwardNgramModel(tokens, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af9cbd",
   "metadata": {
    "id": "38af9cbd"
   },
   "source": [
    "# Generate Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658deb01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "658deb01",
    "outputId": "3b4c9262-d624-401a-bfc3-e4cd3f09c5b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "فاصلہ دھلے ہوجاتے بھرا وفا دیں نصابوں چپ دھتکار\n",
      "ملن کو تنہائیاں پوشاک جیتا قیصرؔ خوش دروازے دورازکار\n",
      "ہمیشہ ہوں!کیا جلتی نہایت پائے چپکے تھکن معینہ سرکار\n",
      "غالبؔ ترک سنتی قمرؔ تیوہار دکھتا مے حامل افکار\n",
      "\n",
      "حویلی ڈبہ انورؔ خواں دیدۂ لحظہ ممتاز جانا تیرتے\n",
      "نگہبان چرچا روگ امتحان آتا ریل زلفوں کیسے ہوسکتی\n",
      "مٹائے شخصیت چھایا ناکافی ڈور دیوالی انھوں دیواروں سکتی\n",
      "جانو خلوت رہگذر کتابیں بدلی کوئی محروم سینا ہوسکتی\n",
      "\n",
      "ہوکر جشن گھسیٹتے پھونک دھتکار حب بندھے پھونکتے صلاحیتیں\n",
      "فرش آنکھ سامعین گار گریاں مولا بیٹیاں یہاں ضرورتیں\n",
      "جاگنے رحمت تعریف آخری پھیلاؤ نگاہ مخل لکھنے آیتیں\n",
      "شعلوں بند طفلان شکوے حادثہ طرز بنے ایماں شکایتیں\n",
      "\n",
      "تیرے پہچانتی دیئے حالانکہ وہیں سراب بن معینہ نواحی\n",
      "فانیؔ دھیرے پیچیدہ ہوتے نعمت نقطے جگر شے دوالی\n",
      "پیسہ پیارا داریاں مہیا چھت سنا سوا حنائی خیالی\n",
      "گھنا تیشے ؎ سانسو عکس جاؤں قصہ جاتا گلالی\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numOfStanzas = 4\n",
    "verseLength = random.randint(7, 10)\n",
    "\n",
    "for _ in range(numOfStanzas):\n",
    "    #generate stanza using bigram model\n",
    "    stanza = generateStanza(bigramModel, verseLength, 4)\n",
    "    for verse in stanza:\n",
    "        print(verse)\n",
    "    print()  # Empty line after each stanza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9356b6",
   "metadata": {
    "id": "1c9356b6"
   },
   "source": [
    "# Comparison of bigram and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83710d2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83710d2e",
    "outputId": "894d16a5-aae8-471d-b3aa-9b8e7e43122a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Bigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Bigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Bigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Bigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Trigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Trigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Trigram Stanza Perplexity: 1.0\n",
      "0.0\n",
      "Trigram Stanza Perplexity: 1.0\n"
     ]
    }
   ],
   "source": [
    "numStanzas = 4\n",
    "verseLength = random.randint(7, 10)\n",
    "bigramStanzas = []\n",
    "trigramStanzas = []\n",
    "\n",
    "#generate stanzas using the bigram and trigram models for comparison\n",
    "for _ in range(numStanzas):\n",
    "    bigramStanza = generateStanza(bigramModel, verseLength, 4)\n",
    "    bigramStanzas.append(bigramStanza)\n",
    "    trigramStanza = generateStanza(trigramModel, verseLength, 4)\n",
    "    trigramStanzas.append(trigramStanza)\n",
    "\n",
    "def calculateApproximatePerplexity(model, text):\n",
    "    logLikelihood = 0.0\n",
    "    numWords = 0\n",
    "\n",
    "    for i in range(len(text) - 2):\n",
    "        if model.get(tuple(text[i:i+2])):\n",
    "            nextWordProb = model[tuple(text[i:i+2])][text[i + 2]]  #get probability of next word\n",
    "            logLikelihood += math.log(nextWordProb)  #update log likelihood\n",
    "    numWords += 1\n",
    "\n",
    "    print(logLikelihood) #for debugging\n",
    "    return math.exp(-logLikelihood / max(numWords, 1))  #calculate perplexity\n",
    "\n",
    "for stanza in bigramStanzas:\n",
    "    bigramText = ' '.join([verse for verse in stanza])\n",
    "    bigramApproxPerplexity = calculateApproximatePerplexity(bigramModel, bigramText)\n",
    "    print(\"Bigram Stanza Perplexity:\", bigramApproxPerplexity)\n",
    "\n",
    "for stanza in trigramStanzas:\n",
    "    trigramText = ' '.join([verse for verse in stanza])\n",
    "    trigramApproxPerplexity = calculateApproximatePerplexity(trigramModel, trigramText)\n",
    "    print(\"Trigram Stanza Perplexity:\", trigramApproxPerplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c3f0f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note:** I have tried my best to provide accurate results in this notebook. However, these results may not be entirely accurate, and contributions or corrections are encouraged. Thank you!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
